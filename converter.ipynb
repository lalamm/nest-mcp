{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab90c0a-6300-4b03-a3ee-c436929e9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fc5663-714f-4bfc-8efc-5fa263d4b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_multiplier(api_code, default_multiplier=1000):\n",
    "    \"\"\"\n",
    "    Returns the multiplier for a given API code.\n",
    "    \n",
    "    Args:\n",
    "        api_code: The financial API code (e.g., 'SI', 'ANT', 'EKA')\n",
    "        default_multiplier: Multiplier for monetary values (default: 1000)\n",
    "    \n",
    "    Returns:\n",
    "        int: Multiplier value (1 for no change, default_multiplier for monetary values)\n",
    "    \"\"\"\n",
    "    \n",
    "    # API codes that should be multiplied (monetary values in thousands)\n",
    "    MONETARY_CODES = {\n",
    "        # Revenue Items\n",
    "        'ADI', 'SDI', 'SI', 'IPA', 'IPI', 'IPT', 'LI', 'costs', 'bruttofort',\n",
    "        \n",
    "        # Expense Items  \n",
    "        'ADK', 'SDK', 'LTP', 'PNKO', 'FOU', 'VF', 'PERSOMK', 'FU', 'loner_ovriga',\n",
    "        'loner_styrelse_vd', 'summa_rorelsekostnader',\n",
    "        \n",
    "        # Asset Items\n",
    "        'SED', 'SAM', 'SOM', 'SV', 'SVA', 'SF', 'KBP', 'EB', 'MI', 'MOA', 'AOM',\n",
    "        'ANF', 'ANFF', 'AFA', 'SFA', 'SIA', 'AIM', 'GLA', 'KPL', 'SRF', 'AAM',\n",
    "        'AID', 'IFS', 'ITS', 'IAA', 'AIV', 'SIV', 'IVEI', 'AFM', 'AMF', 'balance',\n",
    "        'IMMA', 'DRM', 'other_property_plant_and_equipment', 'MAI', 'noncurrent_investments',\n",
    "        'KAPI', 'other_noncurrent_financial_assets', 'FAA', 'anlagsaktiviteter',\n",
    "        'VL', 'TFST', 'THNP', 'ATG', 'VP', 'likvider', 'OMAI', 'summa_finansiella_anltillg',\n",
    "        'other_intangible_assets',\n",
    "        \n",
    "        # Liability & Equity Items\n",
    "        'SEK', 'AK', 'SG', 'SKG', 'SLG', 'LG', 'PG', 'AEK', 'AEKK', 'IRK', 'SIK',\n",
    "        'SOK', 'AKG', 'AKR', 'ALG', 'ALK', 'ANLG', 'GTD', 'GTI', 'MAS', 'SKGKI',\n",
    "        'KL', 'KVL', 'KSL', 'LFK', 'LTK', 'OBL', 'OBLG', 'PST', 'US', 'USF',\n",
    "        'EFMA', 'USKAT', 'hensettelser', 'long_term_mortgage_debt', 'long_term_debt_to_banks',\n",
    "        'LGNP', 'other_long_term_debt', 'ANSVL', 'KGNP', 'short_term_mortgage_debt',\n",
    "        'short_term_debt_to_banks', 'VK', 'AG', 'PASSI', 'summa_langfristiga_skulder',\n",
    "        \n",
    "        # Financial Items\n",
    "        'AFI', 'FI', 'FK', 'AFK', 'AFKK', 'ARI', 'ARK', 'RFF', 'RTK', 'NF', 'NFA',\n",
    "        'NFO', 'FPN', 'other_net_financial_income',\n",
    "        \n",
    "        # Results & Special Items\n",
    "        'DR', 'OR', 'ORS', 'AARS', 'AARK', 'PR', 'EI', 'EK', 'NE', 'EXP', 'SKATAAR',\n",
    "        'KB', 'MU', 'FSUB', 'UTB', 'SUB', 'SUBE', 'SUBT', 'AVUB', 'resultat_e_avskrivningar',\n",
    "        'resultat_e_finansnetto',\n",
    "        \n",
    "        # Provisions & Adjustments\n",
    "        'SAP', 'AVS', 'AFV', 'FFUG', 'OFUG', 'PF', 'PSM', 'SOVE', 'OAE', 'OAEE',\n",
    "        'OTFF', 'TPF', 'NVD', 'ORA', 'VAFI', 'VMF', 'VMFO', 'VØKF', 'VØKI',\n",
    "        \n",
    "        # Cash Flow Items\n",
    "        'KON1', 'KON2', 'KON3', 'KON4', 'KON5', 'KON6', 'KON8', 'KON9', 'KON10',\n",
    "        'UBNKA', 'KON11', 'LIMKA', 'KON12', 'KBPS',\n",
    "        \n",
    "        # Working Capital & Inventory\n",
    "        'ARKA', 'AV', 'BE', 'BEE', 'BEEA', 'BET', 'EBEF', 'VBI', 'OOF', 'OOF3',\n",
    "        \n",
    "        # Taxes & Fees\n",
    "        'BS', 'SKO', 'SKR', 'OFA', 'short_term_tax_payables', 'SLF', 'REVAN', 'REVHO',\n",
    "        \n",
    "        # Other Special Items\n",
    "        'EGA', 'MAK', 'MAO', 'AKSB', 'FONE', 'LEDPS', 'LL', 'ANDLØ', 'OBLNM',\n",
    "        'KSK', 'MIN', 'MINK', 'MA', 'KUF', 'ANIE', 'GTS', 'HUSLK', 'OER', 'OVR'\n",
    "    }\n",
    "    \n",
    "    # Return multiplier if code is monetary, otherwise return 1\n",
    "    return default_multiplier if api_code in MONETARY_CODES else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5667e28d-a12a-4012-80e2-4a9022d22cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_csv(\"raw/Supabase Snippet Update Company Background Images.csv\")\n",
    "codes = pd.read_csv(\"raw/codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b07a212-6a34-4598-92e2-4c19b0084dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = (codes.set_index(\"API_CODE\").DESCRIPTION_ENGLISH).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9b3d9b-29d9-4414-9859-1ed8b8693e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = []\n",
    "for (_,company) in companies.iterrows():\n",
    "    annual_accounts = json.loads(company.annual_accounts)\n",
    "    items = []\n",
    "    for annual_year in annual_accounts:\n",
    "        for item in annual_year[\"accounts\"]:\n",
    "            if item[\"code\"] not in mapper:\n",
    "                #print(\"missing\",item[\"code\"],item[\"amount\"])\n",
    "                continue\n",
    "            else:\n",
    "                if item[\"amount\"] is None:\n",
    "                    continue\n",
    "        \n",
    "                key = mapper[item[\"code\"]]\n",
    "                value = float(item[\"amount\"])\n",
    "                if \"%\" in key:\n",
    "                    value/=100\n",
    "                    key = key.replace(\" in %\",\"\")\n",
    "                    #print(key,value)\n",
    "                value *= get_financial_multiplier(item[\"code\"])\n",
    "                    \n",
    "                #We should fix so its correct value here... somethimes percentage, soemtime SEK, sometimes MSEK\n",
    "                items.append([annual_year[\"year\"],key,value])\n",
    "    company_dict = company[[\"company_id\",\"name\",\"organization_number\",\"company_type\",\"company_purpose\",\"established_date\",\"foundation_year\",\"registered_for_payroll_tax\",\"homepage\",\"postal_address\",\"visitor_address\",\"nace_categories\",\"location\"]].to_dict()\n",
    "    if len(items):\n",
    "        company_dict[\"financiaL_data\"] = json.loads(pd.DataFrame(items).pivot_table(index=0,columns=1,values=2).to_json(orient=\"index\"))\n",
    "    cleaned.append(company_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c05577-cb96-4a3a-85c6-4ea290aeced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cleaned).to_parquet(\"hello_nest_2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f620693d-1bd8-4e0b-b3c2-8e3c94260b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      " pd.pivot_table(\n",
      "    data: \u001b[33m'DataFrame'\u001b[39m,\n",
      "    values=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    index=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    aggfunc: \u001b[33m'AggFuncType'\u001b[39m = \u001b[33m'mean'\u001b[39m,\n",
      "    fill_value=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    margins: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    dropna: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    margins_name: \u001b[33m'Hashable'\u001b[39m = \u001b[33m'All'\u001b[39m,\n",
      "    observed: \u001b[33m'bool | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    sort: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      ") -> \u001b[33m'DataFrame'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Create a spreadsheet-style pivot table as a DataFrame.\n",
      "\n",
      "The levels in the pivot table will be stored in MultiIndex objects\n",
      "(hierarchical indexes) on the index and columns of the result DataFrame.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : DataFrame\n",
      "values : list-like or scalar, optional\n",
      "    Column or columns to aggregate.\n",
      "index : column, Grouper, array, or list of the previous\n",
      "    Keys to group by on the pivot table index. If a list is passed,\n",
      "    it can contain any of the other types (except list). If an array is\n",
      "    passed, it must be the same length as the data and will be used in\n",
      "    the same manner as column values.\n",
      "columns : column, Grouper, array, or list of the previous\n",
      "    Keys to group by on the pivot table column. If a list is passed,\n",
      "    it can contain any of the other types (except list). If an array is\n",
      "    passed, it must be the same length as the data and will be used in\n",
      "    the same manner as column values.\n",
      "aggfunc : function, list of functions, dict, default \"mean\"\n",
      "    If a list of functions is passed, the resulting pivot table will have\n",
      "    hierarchical columns whose top level are the function names\n",
      "    (inferred from the function objects themselves).\n",
      "    If a dict is passed, the key is column to aggregate and the value is\n",
      "    function or list of functions. If ``margin=True``, aggfunc will be\n",
      "    used to calculate the partial aggregates.\n",
      "fill_value : scalar, default None\n",
      "    Value to replace missing values with (in the resulting pivot table,\n",
      "    after aggregation).\n",
      "margins : bool, default False\n",
      "    If ``margins=True``, special ``All`` columns and rows\n",
      "    will be added with partial group aggregates across the categories\n",
      "    on the rows and columns.\n",
      "dropna : bool, default True\n",
      "    Do not include columns whose entries are all NaN. If True,\n",
      "    rows with a NaN value in any column will be omitted before\n",
      "    computing margins.\n",
      "margins_name : str, default 'All'\n",
      "    Name of the row / column that will contain the totals\n",
      "    when margins is True.\n",
      "observed : bool, default False\n",
      "    This only applies if any of the groupers are Categoricals.\n",
      "    If True: only show observed values for categorical groupers.\n",
      "    If False: show all values for categorical groupers.\n",
      "\n",
      "    .. deprecated:: 2.2.0\n",
      "\n",
      "        The default value of ``False`` is deprecated and will change to\n",
      "        ``True`` in a future version of pandas.\n",
      "\n",
      "sort : bool, default True\n",
      "    Specifies if the result should be sorted.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "    An Excel style pivot table.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.pivot : Pivot without aggregation that can handle\n",
      "    non-numeric data.\n",
      "DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      "    optionally leaving identifiers set.\n",
      "wide_to_long : Wide panel to long format. Less flexible but more\n",
      "    user-friendly than melt.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "...                          \"one\", \"one\", \"two\", \"two\"],\n",
      "...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "...                          \"small\", \"large\", \"small\", \"small\",\n",
      "...                          \"large\"],\n",
      "...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      "...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      ">>> df\n",
      "     A    B      C  D  E\n",
      "0  foo  one  small  1  2\n",
      "1  foo  one  large  2  4\n",
      "2  foo  one  large  2  5\n",
      "3  foo  two  small  3  5\n",
      "4  foo  two  small  3  6\n",
      "5  bar  one  large  4  6\n",
      "6  bar  one  small  5  8\n",
      "7  bar  two  small  6  9\n",
      "8  bar  two  large  7  9\n",
      "\n",
      "This first example aggregates values by taking the sum.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "...                        columns=['C'], aggfunc=\"sum\")\n",
      ">>> table\n",
      "C        large  small\n",
      "A   B\n",
      "bar one    4.0    5.0\n",
      "    two    7.0    6.0\n",
      "foo one    4.0    1.0\n",
      "    two    NaN    6.0\n",
      "\n",
      "We can also fill missing values using the `fill_value` parameter.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "...                        columns=['C'], aggfunc=\"sum\", fill_value=0)\n",
      ">>> table\n",
      "C        large  small\n",
      "A   B\n",
      "bar one      4      5\n",
      "    two      7      6\n",
      "foo one      4      1\n",
      "    two      0      6\n",
      "\n",
      "The next example aggregates by taking the mean across multiple columns.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "...                        aggfunc={'D': \"mean\", 'E': \"mean\"})\n",
      ">>> table\n",
      "                D         E\n",
      "A   C\n",
      "bar large  5.500000  7.500000\n",
      "    small  5.500000  8.500000\n",
      "foo large  2.000000  4.500000\n",
      "    small  2.333333  4.333333\n",
      "\n",
      "We can also calculate multiple types of aggregations for any given\n",
      "value column.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "...                        aggfunc={'D': \"mean\",\n",
      "...                                 'E': [\"min\", \"max\", \"mean\"]})\n",
      ">>> table\n",
      "                  D   E\n",
      "               mean max      mean  min\n",
      "A   C\n",
      "bar large  5.500000   9  7.500000    6\n",
      "    small  5.500000   9  8.500000    8\n",
      "foo large  2.000000   5  4.500000    4\n",
      "    small  2.333333   6  4.333333    2\n",
      "\u001b[31mFile:\u001b[39m      ~/.asdf/installs/python/3.11.4/lib/python3.11/site-packages/pandas/core/reshape/pivot.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "? pd.pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d29fed-dd2f-4ada-bd08-95737da9f000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
